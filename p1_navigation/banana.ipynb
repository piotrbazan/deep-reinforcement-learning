{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from envorinment import BananaEnv\n",
    "from experiment import Experiment\n",
    "from agent import DqnAgent\n",
    "from replay_buffer import ReplayBuffer\n",
    "from model import DqnModel\n",
    "from strategy import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment\n",
    "For an experiment we need an agent and an environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found path: /home/pbazan/sources/udacity_drl/p1_navigation/Banana_Linux_NoVis/Banana.x86_64\n",
      "Mono path[0] = '/home/pbazan/sources/udacity_drl/p1_navigation/Banana_Linux_NoVis/Banana_Data/Managed'\n",
      "Mono config path = '/home/pbazan/sources/udacity_drl/p1_navigation/Banana_Linux_NoVis/Banana_Data/MonoBleedingEdge/etc'\n",
      "Preloaded 'libgrpc_csharp_ext.x64.so'\n",
      "Unable to preload the following plugins:\n",
      "\tlibgrpc_csharp_ext.x86.so\n",
      "Logging to /home/pbazan/.config/unity3d/Unity Technologies/Unity Environment/Player.log\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = BananaEnv('Banana_Linux_NoVis/Banana.x86_64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The agent\n",
    "DqnAgent requires several things:\n",
    "- model - a torch model -> `DqnModel`\n",
    "- memory - a reply buffer -> `ReplyBuffer`\n",
    "- train_strategy - one of the strategies like `LinearEpsilonGreedyStrategy` or `ExponentialEpsilonGreedyStrategy`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DqnModel(input_dim=env.nS, output_dim=env.nA, hidden_dims=(64, 64))\n",
    "memory = ReplayBuffer(max_size=10_000)\n",
    "train_strategy = LinearEpsilonGreedyStrategy(eps_start=1., eps_min=.1, decay=.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = DqnAgent(model, memory, train_strategy, ddqn=False, gamma=.9, batch_size=32, train_every=500, update_every=2, tau=1.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = Experiment(env, agent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 50, avg_score: -0.020, agent: {'avg_loss': 0.02473640814423561, 'memory': {'size': 10000}, 'train_strategy': {'epsilon': 0.95}}}}"
     ]
    }
   ],
   "source": [
    "rewards = exp.train(51)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4830d74f2ebad11ac6d10a1fa3e5fe04a0a6a22aaf0203a44e87285205908b5d"
  },
  "kernelspec": {
   "display_name": "pdrl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
